{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"JwRDQeXze9PYfPVq5HTLqXVty\"\n",
    "consumer_secret = \"dbuGIfHlH8Z8T9pza4Va7HKP017C2BJenhRgCRsMho4t6uWqHo\"\n",
    "access_token = \"1308274051228467200-Gb848DLoDkfW6nExVQoZ3QDfiQnWpe\"\n",
    "access_token_secret = \"4JuOwiiuRoVNAAevr6w0ampCe7JYRtXM0y9miXoqQUFtU\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# Authentication testing\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitterscraper():\n",
    "    tweettext=[]\n",
    "    tweetcreated=[]\n",
    "    tweetfaves=[]\n",
    "    tweetuser=[]\n",
    "    tweetlang=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example may no longer show tweets if until_date falls outside \n",
    "# of 7-day period from when you run cell\n",
    "language = 'en'\n",
    "result_type = 'mixed'\n",
    "until_date = '2020-09-30'\n",
    "#teamnews tweet\n",
    "since_id=1310640434193076227\n",
    "#day after tweet\n",
    "max_id=1310976379295596549\n",
    "max_tweets = 50000\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tweepy.Cursor(api.search, lang=language, result_type = result_type, until = until_date, count = 100).items(max_tweets)\n",
    " \n",
    "# List comprehension pulling chosen tweet information from tweets iterable object\n",
    "# Add or remove tweet information you want in the below list comprehension\n",
    "tweets_list = [[tweet.text, tweet.created_at, tweet.id_str,\n",
    "                tweet.favorite_count, tweet.user.screen_name, tweet.user.id_str,\n",
    "                tweet.user.location, tweet.user.url, tweet.user.verified, \n",
    "                tweet.user.followers_count, tweet.user.friends_count, tweet.user.statuses_count, \n",
    "                tweet.user.default_profile_image, tweet.lang] for tweet in tweets]\n",
    " \n",
    "# Creation of dataframe from tweets_list\n",
    "# Did not include column names to simplify code \n",
    "tweets_df = pd.DataFrame(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'Coronavirus'\n",
    "coordinates = '36.169786,-115.139858,50mi'\n",
    "max_tweets = 150\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tweepy.Cursor(api.search, q = text_query, geocode = coordinates, count = 100).items(max_tweets)\n",
    " \n",
    "# Pulling information from tweets iterable object\n",
    "# Add or remove tweet information you want in the below list comprehension\n",
    "tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.favorite_count, tweet.user.screen_name, tweet.user.id_str, tweet.user.location, tweet.user.followers_count, tweet.coordinates, tweet.place] for tweet in tweets]\n",
    " \n",
    "# Creation of dataframe from tweets_list\n",
    "# Did not include column names to simplify code\n",
    "tweets_df = pd.DataFrame(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "class TwitterClient(object): \n",
    "    def __init__(self):\n",
    "        # Access Credentials \n",
    "        consumer_key = 'XXXX'\n",
    "        consumer_secret = 'XXXX'\n",
    "        access_token = 'XXXX'\n",
    "        access_token_secret = 'XXXX'\n",
    "try: \n",
    "            # OAuthHandler object \n",
    "            auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print(f\"Error: Twitter Authentication Failed - \\n{str(e)}\") \n",
    "\n",
    "    # Function to fetch tweets\n",
    "    def get_tweets(self, query, maxTweets = 1000): \n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "        sinceId = None\n",
    "        max_id = -1\n",
    "        tweetCount = 0\n",
    "        tweetsPerQry = 100\n",
    "        \n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = self.api.search(q=query, count=tweetsPerQry)\n",
    "                    else:\n",
    "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
    "                                                since_id=sinceId)\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1))\n",
    "                    else:\n",
    "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1),\n",
    "                                                since_id=sinceId)\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "                    \n",
    "                for tweet in new_tweets:\n",
    "                    parsed_tweet = {} \n",
    "                    parsed_tweet['tweets'] = tweet.text \n",
    "\n",
    "                    # appending parsed tweet to tweets list \n",
    "                    if tweet.retweet_count > 0: \n",
    "                        # if tweet has retweets, ensure that it is appended only once \n",
    "                        if parsed_tweet not in tweets: \n",
    "                            tweets.append(parsed_tweet) \n",
    "                    else: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                        \n",
    "                tweetCount += len(new_tweets)\n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = new_tweets[-1].id\n",
    "\n",
    "            except tweepy.TweepError as e:\n",
    "                print(\"Tweepy error : \" + str(e))\n",
    "                break\n",
    "        \n",
    "        return pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "\n",
    "https://towardsdatascience.com/how-to-scrape-more-information-from-tweets-on-twitter-44fd540b8a1f\n",
    "\n",
    "https://github.com/MartinBeckUT/TwitterScraper/tree/master/BasicScraper\n",
    "\n",
    "https://medium.com/analytics-vidhya/how-to-get-trending-tweets-in-any-country-with-python-and-tweepy-af2bfe760251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
