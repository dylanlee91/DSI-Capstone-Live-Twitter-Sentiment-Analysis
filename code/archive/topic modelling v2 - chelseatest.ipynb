{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base and Cleaning \n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import pyLDAvis.gensim\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py \n",
    "import chart_studio.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:73: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import namedtuple, defaultdict, Iterable\n"
     ]
    }
   ],
   "source": [
    "#Natural Language Processing (NLP)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../datasets/chelseapalacetweetscombined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetcreatedts</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>acctdesc</th>\n",
       "      <th>location</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>usercreatedts</th>\n",
       "      <th>retweetcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titomar_758</td>\n",
       "      <td>Chelsea vs Crystal palace. \\n\\n‚Ä¢ Mendy clean s...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canaries st.lucia</td>\n",
       "      <td>973</td>\n",
       "      <td>52301</td>\n",
       "      <td>2014-02-01 20:02:37</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kennyroja191</td>\n",
       "      <td>Wait, this same Crystal Palace flogged Man Utd...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Osun, Nigeria</td>\n",
       "      <td>36</td>\n",
       "      <td>877</td>\n",
       "      <td>2019-12-30 17:20:58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John38466297</td>\n",
       "      <td>Seems like beating Crystal Palace at home this...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maryland, Lagos</td>\n",
       "      <td>37</td>\n",
       "      <td>251</td>\n",
       "      <td>2020-07-15 11:37:58</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damyyllare</td>\n",
       "      <td>üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Ben Chilwell vs Crystal Palace\\n\\n90 m...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>I am a blessing for my generation... I love fi...</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>416</td>\n",
       "      <td>4410</td>\n",
       "      <td>2016-03-15 12:51:50</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Younguzumaki1</td>\n",
       "      <td>I love how Havertz constantly roams around the...</td>\n",
       "      <td>2020-10-03 13:32:06</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Federal Capital Territory, Nig</td>\n",
       "      <td>1346</td>\n",
       "      <td>50678</td>\n",
       "      <td>2012-07-21 15:12:44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                               text  \\\n",
       "0    titomar_758  Chelsea vs Crystal palace. \\n\\n‚Ä¢ Mendy clean s...   \n",
       "1   Kennyroja191  Wait, this same Crystal Palace flogged Man Utd...   \n",
       "2   John38466297  Seems like beating Crystal Palace at home this...   \n",
       "3     damyyllare  üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Ben Chilwell vs Crystal Palace\\n\\n90 m...   \n",
       "4  Younguzumaki1  I love how Havertz constantly roams around the...   \n",
       "\n",
       "        tweetcreatedts hashtags  \\\n",
       "0  2020-10-03 13:32:07       []   \n",
       "1  2020-10-03 13:32:07       []   \n",
       "2  2020-10-03 13:32:07       []   \n",
       "3  2020-10-03 13:32:07       []   \n",
       "4  2020-10-03 13:32:06       []   \n",
       "\n",
       "                                            acctdesc  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  I am a blessing for my generation... I love fi...   \n",
       "4                                                NaN   \n",
       "\n",
       "                         location  followers  totaltweets  \\\n",
       "0               Canaries st.lucia        973        52301   \n",
       "1                   Osun, Nigeria         36          877   \n",
       "2                 Maryland, Lagos         37          251   \n",
       "3                         Nigeria        416         4410   \n",
       "4  Federal Capital Territory, Nig       1346        50678   \n",
       "\n",
       "         usercreatedts  retweetcount  \n",
       "0  2014-02-01 20:02:37            77  \n",
       "1  2019-12-30 17:20:58            59  \n",
       "2  2020-07-15 11:37:58           994  \n",
       "3  2016-03-15 12:51:50            65  \n",
       "4  2012-07-21 15:12:44             7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9703\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    \"\"\"\n",
    "    Removes emoji's from tweets\n",
    "    Accepts:\n",
    "        Text (tweets)\n",
    "    Returns:\n",
    "        Text (emoji free tweets)\n",
    "    \"\"\"\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def url_free_text(text):\n",
    "    '''\n",
    "    Cleans text from urls\n",
    "    '''\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_usernames(text):\n",
    "    text=re.sub(r'\\B@\\w+', 'USERNAME', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "df['emoji_free_tweets'] = df['text'].apply(call_emoji_free)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)\n",
    "\n",
    "#create new column with username free tweets\n",
    "df['remove_usernames'] = df['url_free_tweets'].apply(remove_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetcreatedts</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>acctdesc</th>\n",
       "      <th>location</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>usercreatedts</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>emoji_free_tweets</th>\n",
       "      <th>url_free_tweets</th>\n",
       "      <th>remove_usernames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titomar_758</td>\n",
       "      <td>Chelsea vs Crystal palace. \\n\\n‚Ä¢ Mendy clean s...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canaries st.lucia</td>\n",
       "      <td>973</td>\n",
       "      <td>52301</td>\n",
       "      <td>2014-02-01 20:02:37</td>\n",
       "      <td>77</td>\n",
       "      <td>Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...</td>\n",
       "      <td>Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...</td>\n",
       "      <td>Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kennyroja191</td>\n",
       "      <td>Wait, this same Crystal Palace flogged Man Utd...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Osun, Nigeria</td>\n",
       "      <td>36</td>\n",
       "      <td>877</td>\n",
       "      <td>2019-12-30 17:20:58</td>\n",
       "      <td>59</td>\n",
       "      <td>Wait, this same Crystal Palace flogged Man Utd...</td>\n",
       "      <td>Wait, this same Crystal Palace flogged Man Utd...</td>\n",
       "      <td>Wait, this same Crystal Palace flogged Man Utd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John38466297</td>\n",
       "      <td>Seems like beating Crystal Palace at home this...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maryland, Lagos</td>\n",
       "      <td>37</td>\n",
       "      <td>251</td>\n",
       "      <td>2020-07-15 11:37:58</td>\n",
       "      <td>994</td>\n",
       "      <td>Seems like beating Crystal Palace at home this...</td>\n",
       "      <td>Seems like beating Crystal Palace at home this...</td>\n",
       "      <td>Seems like beating Crystal Palace at home this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damyyllare</td>\n",
       "      <td>üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Ben Chilwell vs Crystal Palace\\n\\n90 m...</td>\n",
       "      <td>2020-10-03 13:32:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>I am a blessing for my generation... I love fi...</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>416</td>\n",
       "      <td>4410</td>\n",
       "      <td>2016-03-15 12:51:50</td>\n",
       "      <td>65</td>\n",
       "      <td>Ben Chilwell vs Crystal Palace 90 minutes play...</td>\n",
       "      <td>Ben Chilwell vs Crystal Palace 90 minutes play...</td>\n",
       "      <td>Ben Chilwell vs Crystal Palace 90 minutes play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Younguzumaki1</td>\n",
       "      <td>I love how Havertz constantly roams around the...</td>\n",
       "      <td>2020-10-03 13:32:06</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Federal Capital Territory, Nig</td>\n",
       "      <td>1346</td>\n",
       "      <td>50678</td>\n",
       "      <td>2012-07-21 15:12:44</td>\n",
       "      <td>7</td>\n",
       "      <td>I love how Havertz constantly roams around the...</td>\n",
       "      <td>I love how Havertz constantly roams around the...</td>\n",
       "      <td>I love how Havertz constantly roams around the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9698</th>\n",
       "      <td>schoolBoyfrm5th</td>\n",
       "      <td>Ben Chilwell has lost possession (5) more time...</td>\n",
       "      <td>2020-10-03 13:14:15</td>\n",
       "      <td>[]</td>\n",
       "      <td>yooohooooo\\n   bastard of the east blue</td>\n",
       "      <td>village hidden in the tits</td>\n",
       "      <td>1906</td>\n",
       "      <td>36980</td>\n",
       "      <td>2017-06-29 16:20:52</td>\n",
       "      <td>587</td>\n",
       "      <td>Ben Chilwell has lost possession (5) more time...</td>\n",
       "      <td>Ben Chilwell has lost possession (5) more time...</td>\n",
       "      <td>Ben Chilwell has lost possession (5) more time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>Tamar__lee</td>\n",
       "      <td>Is this the crystal palace that beat Man U?</td>\n",
       "      <td>2020-10-03 13:14:14</td>\n",
       "      <td>[]</td>\n",
       "      <td>watched by angels.,protected by God</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>1006</td>\n",
       "      <td>18683</td>\n",
       "      <td>2012-12-06 17:06:31</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this the crystal palace that beat Man U?</td>\n",
       "      <td>Is this the crystal palace that beat Man U?</td>\n",
       "      <td>Is this the crystal palace that beat Man U?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>I_am_Tangeni</td>\n",
       "      <td>Ano, TF is up with Palace? Can‚Äôt believe we go...</td>\n",
       "      <td>2020-10-03 13:14:14</td>\n",
       "      <td>['CHECRY']</td>\n",
       "      <td>Beer Drinkers Hall of Fame, #Father #Son #Brot...</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>1543</td>\n",
       "      <td>64100</td>\n",
       "      <td>2011-12-11 08:18:19</td>\n",
       "      <td>1</td>\n",
       "      <td>Ano, TF is up with Palace? Can‚Äôt believe we go...</td>\n",
       "      <td>Ano, TF is up with Palace? Can‚Äôt believe we go...</td>\n",
       "      <td>Ano, TF is up with Palace? Can‚Äôt believe we go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>Arsenal_LINY</td>\n",
       "      <td>It just keeps getting worst for Crystal Palace...</td>\n",
       "      <td>2020-10-03 13:14:13</td>\n",
       "      <td>['checry']</td>\n",
       "      <td>Supporting Arsenal Football Club #COYG</td>\n",
       "      <td>Long Island, NY</td>\n",
       "      <td>386</td>\n",
       "      <td>11668</td>\n",
       "      <td>2016-12-11 18:32:21</td>\n",
       "      <td>0</td>\n",
       "      <td>It just keeps getting worst for Crystal Palace...</td>\n",
       "      <td>It just keeps getting worst for Crystal Palace...</td>\n",
       "      <td>It just keeps getting worst for Crystal Palace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>Independent</td>\n",
       "      <td>GOAL! Jorginho adds a second following row wit...</td>\n",
       "      <td>2020-10-03 13:14:13</td>\n",
       "      <td>['CFC', 'CPFC']</td>\n",
       "      <td>News, comment and features from The Independen...</td>\n",
       "      <td>London, England</td>\n",
       "      <td>3343023</td>\n",
       "      <td>1035201</td>\n",
       "      <td>2008-10-26 00:00:29</td>\n",
       "      <td>4</td>\n",
       "      <td>GOAL! Jorginho adds a second following row wit...</td>\n",
       "      <td>GOAL! Jorginho adds a second following row wit...</td>\n",
       "      <td>GOAL! Jorginho adds a second following row wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9703 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                                               text  \\\n",
       "0         titomar_758  Chelsea vs Crystal palace. \\n\\n‚Ä¢ Mendy clean s...   \n",
       "1        Kennyroja191  Wait, this same Crystal Palace flogged Man Utd...   \n",
       "2        John38466297  Seems like beating Crystal Palace at home this...   \n",
       "3          damyyllare  üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Ben Chilwell vs Crystal Palace\\n\\n90 m...   \n",
       "4       Younguzumaki1  I love how Havertz constantly roams around the...   \n",
       "...               ...                                                ...   \n",
       "9698  schoolBoyfrm5th  Ben Chilwell has lost possession (5) more time...   \n",
       "9699       Tamar__lee        Is this the crystal palace that beat Man U?   \n",
       "9700     I_am_Tangeni  Ano, TF is up with Palace? Can‚Äôt believe we go...   \n",
       "9701     Arsenal_LINY  It just keeps getting worst for Crystal Palace...   \n",
       "9702      Independent  GOAL! Jorginho adds a second following row wit...   \n",
       "\n",
       "           tweetcreatedts         hashtags  \\\n",
       "0     2020-10-03 13:32:07               []   \n",
       "1     2020-10-03 13:32:07               []   \n",
       "2     2020-10-03 13:32:07               []   \n",
       "3     2020-10-03 13:32:07               []   \n",
       "4     2020-10-03 13:32:06               []   \n",
       "...                   ...              ...   \n",
       "9698  2020-10-03 13:14:15               []   \n",
       "9699  2020-10-03 13:14:14               []   \n",
       "9700  2020-10-03 13:14:14       ['CHECRY']   \n",
       "9701  2020-10-03 13:14:13       ['checry']   \n",
       "9702  2020-10-03 13:14:13  ['CFC', 'CPFC']   \n",
       "\n",
       "                                               acctdesc  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     I am a blessing for my generation... I love fi...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "9698            yooohooooo\\n   bastard of the east blue   \n",
       "9699                watched by angels.,protected by God   \n",
       "9700  Beer Drinkers Hall of Fame, #Father #Son #Brot...   \n",
       "9701             Supporting Arsenal Football Club #COYG   \n",
       "9702  News, comment and features from The Independen...   \n",
       "\n",
       "                            location  followers  totaltweets  \\\n",
       "0                  Canaries st.lucia        973        52301   \n",
       "1                      Osun, Nigeria         36          877   \n",
       "2                    Maryland, Lagos         37          251   \n",
       "3                            Nigeria        416         4410   \n",
       "4     Federal Capital Territory, Nig       1346        50678   \n",
       "...                              ...        ...          ...   \n",
       "9698      village hidden in the tits       1906        36980   \n",
       "9699                         Nigeria       1006        18683   \n",
       "9700                         Namibia       1543        64100   \n",
       "9701                 Long Island, NY        386        11668   \n",
       "9702                 London, England    3343023      1035201   \n",
       "\n",
       "            usercreatedts  retweetcount  \\\n",
       "0     2014-02-01 20:02:37            77   \n",
       "1     2019-12-30 17:20:58            59   \n",
       "2     2020-07-15 11:37:58           994   \n",
       "3     2016-03-15 12:51:50            65   \n",
       "4     2012-07-21 15:12:44             7   \n",
       "...                   ...           ...   \n",
       "9698  2017-06-29 16:20:52           587   \n",
       "9699  2012-12-06 17:06:31             0   \n",
       "9700  2011-12-11 08:18:19             1   \n",
       "9701  2016-12-11 18:32:21             0   \n",
       "9702  2008-10-26 00:00:29             4   \n",
       "\n",
       "                                      emoji_free_tweets  \\\n",
       "0     Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...   \n",
       "1     Wait, this same Crystal Palace flogged Man Utd...   \n",
       "2     Seems like beating Crystal Palace at home this...   \n",
       "3     Ben Chilwell vs Crystal Palace 90 minutes play...   \n",
       "4     I love how Havertz constantly roams around the...   \n",
       "...                                                 ...   \n",
       "9698  Ben Chilwell has lost possession (5) more time...   \n",
       "9699        Is this the crystal palace that beat Man U?   \n",
       "9700  Ano, TF is up with Palace? Can‚Äôt believe we go...   \n",
       "9701  It just keeps getting worst for Crystal Palace...   \n",
       "9702  GOAL! Jorginho adds a second following row wit...   \n",
       "\n",
       "                                        url_free_tweets  \\\n",
       "0     Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...   \n",
       "1     Wait, this same Crystal Palace flogged Man Utd...   \n",
       "2     Seems like beating Crystal Palace at home this...   \n",
       "3     Ben Chilwell vs Crystal Palace 90 minutes play...   \n",
       "4     I love how Havertz constantly roams around the...   \n",
       "...                                                 ...   \n",
       "9698  Ben Chilwell has lost possession (5) more time...   \n",
       "9699        Is this the crystal palace that beat Man U?   \n",
       "9700  Ano, TF is up with Palace? Can‚Äôt believe we go...   \n",
       "9701  It just keeps getting worst for Crystal Palace...   \n",
       "9702  GOAL! Jorginho adds a second following row wit...   \n",
       "\n",
       "                                       remove_usernames  \n",
       "0     Chelsea vs Crystal palace. ‚Ä¢ Mendy clean sheet...  \n",
       "1     Wait, this same Crystal Palace flogged Man Utd...  \n",
       "2     Seems like beating Crystal Palace at home this...  \n",
       "3     Ben Chilwell vs Crystal Palace 90 minutes play...  \n",
       "4     I love how Havertz constantly roams around the...  \n",
       "...                                                 ...  \n",
       "9698  Ben Chilwell has lost possession (5) more time...  \n",
       "9699        Is this the crystal palace that beat Man U?  \n",
       "9700  Ano, TF is up with Palace? Can‚Äôt believe we go...  \n",
       "9701  It just keeps getting worst for Crystal Palace...  \n",
       "9702  GOAL! Jorginho adds a second following row wit...  \n",
       "\n",
       "[9703 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Custom stopwords\n",
    "custom_stopwords = ['hi','\\n','\\n\\n', '&amp;', '&gt;', '&lt', ' ', '.', '-', 'got', \"it's\", 'it‚Äôs', \"i'm\", 'i‚Äôm', 'im', 'want', 'like', '$', '@']\n",
    "\n",
    "# Customize stop words by adding to the default list\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(custom_stopwords)\n",
    "\n",
    "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
    "ALL_STOP_WORDS = STOP_WORDS.union(SW).union(stopwords)\n",
    "\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['remove_usernames'], batch_size=500):\n",
    "    doc_tokens = []    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())   \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokens a string again\n",
    "df['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df['tokens']]\n",
    "\n",
    "def get_lemmas(text):\n",
    "    '''Used to lemmatize the processed tweets'''\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['tokens_back_to_text'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lemmas a string again\n",
    "df['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in df['lemmas']]\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Parses a string into a list of semantic units (words)\n",
    "    Args:\n",
    "        text (str): The string that the function will tokenize.\n",
    "    Returns:\n",
    "        list: tokens parsed out\n",
    "    \"\"\"\n",
    "    # Removing url's\n",
    "    pattern = r\"http\\S+\"\n",
    "    \n",
    "    tokens = re.sub(pattern, \"\", text) # https://www.youtube.com/watch?v=O2onA4r5UaY\n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    tokens = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
    "    tokens = re.sub('@*!*\\$*', '', text) # Remove @ ! $\n",
    "    tokens = tokens.strip(',') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('?') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('!') # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\"'\") # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\".\") # TESTING THIS LINE\n",
    "\n",
    "    tokens = tokens.lower().split() # Make text lowercase and split it\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenizer\n",
    "df['lemma_tokens'] = df['lemmas_back_to_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136\n"
     ]
    }
   ],
   "source": [
    "# Create a id2word dictionary\n",
    "id2word = Dictionary(df['lemma_tokens'])\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408\n"
     ]
    }
   ],
   "source": [
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a Base LDA model \n",
    "base_model = LdaMulticore(corpus=corpus, num_topics=5, id2word=id2word, workers=12, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for words \n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "palace crystal chelsea checry 0 beat goal home 4 season\n",
      "\n",
      "------ Topic 1 ------\n",
      "palace crystal chelsea vs watch league live retweet mobile match\n",
      "\n",
      "------ Topic 2 ------\n",
      "palace chelsea crystal live ‚óâ checry vs today vs. username\n",
      "\n",
      "------ Topic 3 ------\n",
      "palace ‚óâ crystal 2 = chelsea win 0 havertz goal\n",
      "\n",
      "------ Topic 4 ------\n",
      "palace crystal username chilwell time lose player minute 10 open\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -5.2932225154451\n",
      "\n",
      "Coherence Score:  0.3740063227699808\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "# a measure of how good the model is. lower the better\n",
    "base_perplexity = base_model.log_perplexity(corpus)\n",
    "print('\\nPerplexity: ', base_perplexity) \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model = CoherenceModel(model=base_model, texts=df['lemma_tokens'], \n",
    "                                   dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_model_base = coherence_model.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "This notebook is built with the help of this article\n",
    "\n",
    "https://towardsdatascience.com/twitter-topic-modeling-e0e3315b12e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further References\n",
    "\n",
    "https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44177986/replacing-twitter-usernames-with-username-how-to/44178977#44178977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
