{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base and Cleaning \n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import pyLDAvis.gensim\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py \n",
    "import chart_studio.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:73: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import namedtuple, defaultdict, Iterable\n"
     ]
    }
   ],
   "source": [
    "#Natural Language Processing (NLP)\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../datasets/tweetstreamresults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>text</th>\n",
       "      <th>quoted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>justincroser</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>COME ON REDS!! üî¥üî¥ Have to sleep for work but h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>LFCYNWA125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @LFC: J√ºrgen Klopp provides detail on the s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>itstugenfinest</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @SkySportsPL: 'I'm pretty sure he won't be ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>guu_mendees</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @ludovicofans: Now follow the news  ¬†¬†¬† ¬† L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>justindivine5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>RT @AnfieldWatch: Jurgen Klopp: ‚ÄúIt‚Äôs an inter...</td>\n",
       "      <td>Liverpool face an anxious wait on how long the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date            user  is_retweet  is_quote  \\\n",
       "0  4/10/2020 18:10    justincroser       False     False   \n",
       "1  4/10/2020 18:10      LFCYNWA125        True     False   \n",
       "2  4/10/2020 18:10  itstugenfinest        True     False   \n",
       "3  4/10/2020 18:10     guu_mendees        True     False   \n",
       "4  4/10/2020 18:10   justindivine5        True      True   \n",
       "\n",
       "                                                text  \\\n",
       "0  COME ON REDS!! üî¥üî¥ Have to sleep for work but h...   \n",
       "1  RT @LFC: J√ºrgen Klopp provides detail on the s...   \n",
       "2  RT @SkySportsPL: 'I'm pretty sure he won't be ...   \n",
       "3  RT @ludovicofans: Now follow the news  ¬†¬†¬† ¬† L...   \n",
       "4  RT @AnfieldWatch: Jurgen Klopp: ‚ÄúIt‚Äôs an inter...   \n",
       "\n",
       "                                         quoted_text  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  Liverpool face an anxious wait on how long the...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    309532\n",
       "True        133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1          True\n",
       "2          True\n",
       "3          True\n",
       "4          True\n",
       "          ...  \n",
       "309660     True\n",
       "309661    False\n",
       "309662     True\n",
       "309663    False\n",
       "309664     True\n",
       "Name: is_retweet, Length: 309665, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_retweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the dataframe to only look at original tweets for now\n",
    "df = df.loc[df['is_retweet']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "villa = ['dean smith', 'martinez', 'emi','cash', 'konsa', 'ming', 'targett', 'luiz', 'mcginn', 'grealish', 'trezeguet', 'barkley', 'watkins','traore']\n",
    "liverpool = ['klopp', 'salah', 'mane', 'firmino', 'adrian', 'vvd', 'van dijk', 'gomez', 'robertson', 'robbo', 'wijnaldum', 'gini', 'minamino', 'trent', 'taa', 'keita', 'fabinho', 'jones', 'milner']\n",
    "playerlist=villa+liverpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    \"\"\"\n",
    "    Removes emoji's from tweets\n",
    "    Accepts:\n",
    "        Text (tweets)\n",
    "    Returns:\n",
    "        Text (emoji free tweets)\n",
    "    \"\"\"\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def url_free_text(text):\n",
    "    '''\n",
    "    Cleans text from urls\n",
    "    '''\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_usernames(text):\n",
    "    text=re.sub(r'\\B@\\w+', 'username', text)\n",
    "    return text\n",
    "\n",
    "def player_regex(text, playerlist = playerlist):\n",
    "    output=[]\n",
    "    for name in playerlist:\n",
    "        characters=['\\\\b']\n",
    "        for letter in list(name.lower()):\n",
    "            characters.append('([')\n",
    "            characters.append(letter.upper())\n",
    "            characters.append(letter.lower())\n",
    "            characters.append(']+)')\n",
    "        entry=''.join(characters)\n",
    "        output.append(entry)\n",
    "    for i,j in zip(output,playerlist):\n",
    "        text = re.sub(i, j, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "df['cleantext'] = df['text'].apply(call_emoji_free).apply(url_free_text).apply(remove_usernames).apply(player_regex)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "#df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)\n",
    "\n",
    "#create new column with username free tweets\n",
    "#df['remove_usernames'] = df['url_free_tweets'].apply(remove_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>text</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>justincroser</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>COME ON REDS!! üî¥üî¥ Have to sleep for work but h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COME ON REDS!! Have to sleep for work but hopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>GlazersOutSzn</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@samuelluckhurst #GlazersOut</td>\n",
       "      <td>+/- 7 years  SEVEN YEARS AFTER SAF retired  wh...</td>\n",
       "      <td>username #GlazersOut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>iSuperFrank</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ÿßŸÑŸÖÿ™ÿπÿ© ŸÖÿπ ÿ¨ÿßŸÉŸä ÿ®ŸàŸä Ÿà ÿßŸÑŸÖÿ±ÿ®ÿπ</td>\n",
       "      <td>üü£ ùóß ùóò ùóî ùó†  ùó° ùóò ùó™ ùó¶ üü£  @RBarkley8 makes his Ast...</td>\n",
       "      <td>ÿßŸÑŸÖÿ™ÿπÿ© ŸÖÿπ ÿ¨ÿßŸÉŸä ÿ®ŸàŸä Ÿà ÿßŸÑŸÖÿ±ÿ®ÿπ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>KRSNQ1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>LOL WE ARE CONCEDING GOALS TODAY PMDS üò§üò§üò§ IF W...</td>\n",
       "      <td>J√ºrgen Klopp provides detail on the shoulder i...</td>\n",
       "      <td>LOL WE ARE CONCEDING GOALS TODAY PMDS IF WE DO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4/10/2020 18:10</td>\n",
       "      <td>WIANDJO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;gt;&amp;gt;&amp;gt; WATCH Aston Villa vs Liverpool LI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;gt;&amp;gt;&amp;gt; WATCH Aston Villa vs Liverpool LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309656</th>\n",
       "      <td>4/10/2020 20:20</td>\n",
       "      <td>benihime_sensei</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Liverpool vient de se prendre 7 buts par Aston...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liverpool vient de se prendre 7 buts par Aston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309658</th>\n",
       "      <td>4/10/2020 20:20</td>\n",
       "      <td>notbitterbetter</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Villa were poor there  should‚Äôve scored 10 or 11.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Villa were poor there should‚Äôve scored 10 or 11.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309659</th>\n",
       "      <td>4/10/2020 20:20</td>\n",
       "      <td>artDante1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good time to be alive...  Manchester United lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good time to be alive... Manchester United los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309661</th>\n",
       "      <td>4/10/2020 20:20</td>\n",
       "      <td>jonesy73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Gutted that we couldn‚Äôt all be there together ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gutted that we couldn‚Äôt all be there together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309663</th>\n",
       "      <td>4/10/2020 20:20</td>\n",
       "      <td>ChizyFootball</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@quentin_gsp On est ensemble c'est magnifique ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>username On est ensemble c'est magnifique ! J ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178166 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date             user  is_retweet  is_quote  \\\n",
       "0       4/10/2020 18:10     justincroser       False     False   \n",
       "5       4/10/2020 18:10    GlazersOutSzn       False      True   \n",
       "6       4/10/2020 18:10      iSuperFrank       False      True   \n",
       "9       4/10/2020 18:10           KRSNQ1       False      True   \n",
       "11      4/10/2020 18:10          WIANDJO       False     False   \n",
       "...                 ...              ...         ...       ...   \n",
       "309656  4/10/2020 20:20  benihime_sensei       False     False   \n",
       "309658  4/10/2020 20:20  notbitterbetter       False     False   \n",
       "309659  4/10/2020 20:20        artDante1       False     False   \n",
       "309661  4/10/2020 20:20         jonesy73       False     False   \n",
       "309663  4/10/2020 20:20    ChizyFootball       False     False   \n",
       "\n",
       "                                                     text  \\\n",
       "0       COME ON REDS!! üî¥üî¥ Have to sleep for work but h...   \n",
       "5                            @samuelluckhurst #GlazersOut   \n",
       "6                             ÿßŸÑŸÖÿ™ÿπÿ© ŸÖÿπ ÿ¨ÿßŸÉŸä ÿ®ŸàŸä Ÿà ÿßŸÑŸÖÿ±ÿ®ÿπ   \n",
       "9       LOL WE ARE CONCEDING GOALS TODAY PMDS üò§üò§üò§ IF W...   \n",
       "11      &gt;&gt;&gt; WATCH Aston Villa vs Liverpool LI...   \n",
       "...                                                   ...   \n",
       "309656  Liverpool vient de se prendre 7 buts par Aston...   \n",
       "309658  Villa were poor there  should‚Äôve scored 10 or 11.   \n",
       "309659  Good time to be alive...  Manchester United lo...   \n",
       "309661  Gutted that we couldn‚Äôt all be there together ...   \n",
       "309663  @quentin_gsp On est ensemble c'est magnifique ...   \n",
       "\n",
       "                                              quoted_text  \\\n",
       "0                                                     NaN   \n",
       "5       +/- 7 years  SEVEN YEARS AFTER SAF retired  wh...   \n",
       "6       üü£ ùóß ùóò ùóî ùó†  ùó° ùóò ùó™ ùó¶ üü£  @RBarkley8 makes his Ast...   \n",
       "9       J√ºrgen Klopp provides detail on the shoulder i...   \n",
       "11                                                    NaN   \n",
       "...                                                   ...   \n",
       "309656                                                NaN   \n",
       "309658                                                NaN   \n",
       "309659                                                NaN   \n",
       "309661                                                NaN   \n",
       "309663                                                NaN   \n",
       "\n",
       "                                                cleantext  \n",
       "0       COME ON REDS!! Have to sleep for work but hopi...  \n",
       "5                                    username #GlazersOut  \n",
       "6                             ÿßŸÑŸÖÿ™ÿπÿ© ŸÖÿπ ÿ¨ÿßŸÉŸä ÿ®ŸàŸä Ÿà ÿßŸÑŸÖÿ±ÿ®ÿπ  \n",
       "9       LOL WE ARE CONCEDING GOALS TODAY PMDS IF WE DO...  \n",
       "11      &gt;&gt;&gt; WATCH Aston Villa vs Liverpool LI...  \n",
       "...                                                   ...  \n",
       "309656  Liverpool vient de se prendre 7 buts par Aston...  \n",
       "309658   Villa were poor there should‚Äôve scored 10 or 11.  \n",
       "309659  Good time to be alive... Manchester United los...  \n",
       "309661  Gutted that we couldn‚Äôt all be there together ...  \n",
       "309663  username On est ensemble c'est magnifique ! J ...  \n",
       "\n",
       "[178166 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Custom stopwords\n",
    "socialmedia_stopwords = ['hi','\\n','\\n\\n', '&amp;', '&gt;', '&lt', ' ', '.', '-', 'got', \"it's\", 'it‚Äôs', \"i'm\", 'i‚Äôm', 'im', 'want', 'like', '$', '@']\n",
    "spanish_stopwords = ['de', 'que', 'el', 'o', 'la', 'en', 'al','del','dey', 'ini',' bu', 'ya', 'et', 'je', 'los', 'lo', 'por', 'le', 'se', 'es']\n",
    "match_terms = ['liverpool', 'avfc', 'aston', 'villa', 'lfc', 'avlliv']\n",
    "custom_stopwords = socialmedia_stopwords + spanish_stopwords + match_terms\n",
    "\n",
    "# Customize stop words by adding to the default list\n",
    "stop_words = nlp.Defaults.stop_words.union(custom_stopwords)\n",
    "\n",
    "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
    "final_stop_words = stop_words.union(SW).union(stopwords)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['cleantext'], batch_size=500):\n",
    "    doc_tokens = []    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in final_stop_words:\n",
    "            doc_tokens.append(token.text.lower())   \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokens a string again\n",
    "df['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df['tokens']]\n",
    "\n",
    "def get_lemmas(text):\n",
    "    '''Used to lemmatize the processed tweets'''\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['tokens_back_to_text'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lemmas a string again\n",
    "df['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in df['lemmas']]\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Parses a string into a list of semantic units (words)\n",
    "    Args:\n",
    "        text (str): The string that the function will tokenize.\n",
    "    Returns:\n",
    "        list: tokens parsed out\n",
    "    \"\"\"\n",
    "    # Removing url's\n",
    "    pattern = r\"http\\S+\"\n",
    "    \n",
    "    tokens = re.sub(pattern, \"\", text) # https://www.youtube.com/watch?v=O2onA4r5UaY\n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    tokens = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
    "    tokens = re.sub('@*!*\\$*', '', text) # Remove @ ! $\n",
    "    tokens = tokens.strip(',') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('?') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('!') # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\"'\") # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\".\") # TESTING THIS LINE\n",
    "\n",
    "    tokens = tokens.lower().split() # Make text lowercase and split it\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenizer\n",
    "df['lemma_tokens'] = df['lemmas_back_to_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87507\n"
     ]
    }
   ],
   "source": [
    "# Create a id2word dictionary\n",
    "id2word = Dictionary(df['lemma_tokens'])\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32217\n"
     ]
    }
   ],
   "source": [
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a Base LDA model \n",
    "base_model = LdaMulticore(corpus=corpus, num_topics=10, id2word=id2word, workers=12, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for words \n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "username game watch grass 2 avlliv world lfc liverpool souness\n",
      "\n",
      "------ Topic 1 ------\n",
      "avlliv liverpool avfc goal watkins come score lfc barkley salah\n",
      "\n",
      "------ Topic 2 ------\n",
      "username villa lol wow klopp avlliv go mean come need\n",
      "\n",
      "------ Topic 3 ------\n",
      "1 6 2 lose 4 5 league win man 7\n",
      "\n",
      "------ Topic 4 ------\n",
      "y liverpool ni para premier mu est√° pero una si\n",
      "\n",
      "------ Topic 5 ------\n",
      "2 7 fuck 8 0 avlliv villa liverpool adrian goal\n",
      "\n",
      "------ Topic 6 ------\n",
      "go username fan bad game liverpool look fucking adrian need\n",
      "\n",
      "------ Topic 7 ------\n",
      "e √© liverpool n√£o 7 united t√° mais um username\n",
      "\n",
      "------ Topic 8 ------\n",
      "fan united man username play team utd manchester walk today\n",
      "\n",
      "------ Topic 9 ------\n",
      "username vs live liverpool watch 2020 10 false villa avlliv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.978118537881098\n",
      "\n",
      "Coherence Score:  0.5638913819659411\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "# a measure of how good the model is. lower the better\n",
    "base_perplexity = base_model.log_perplexity(corpus)\n",
    "print('\\nPerplexity: ', base_perplexity) \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model = CoherenceModel(model=base_model, texts=df['lemma_tokens'], \n",
    "                                   dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_model_base = coherence_model.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "This notebook is built with the help of this article\n",
    "\n",
    "https://towardsdatascience.com/twitter-topic-modeling-e0e3315b12e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further References\n",
    "\n",
    "https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44177986/replacing-twitter-usernames-with-username-how-to/44178977#44178977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
